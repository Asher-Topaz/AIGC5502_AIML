import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
from sklearn.model_selection import train_test_split
import warnings


data = pd.read_csv('data_science_salaries.csv')
data.sample(10)


data.dtypes


data.shape


data.describe()


data.info()


#check for duplicates
duplicate_rows = data[data.duplicated()]

# Print or handle the duplicate rows
if not duplicate_rows.empty:
    print("Duplicate Rows except first occurrence:")
    print(duplicate_rows)
else:
    print("No duplicate rows found.")


data.isnull().sum().sort_values(ascending=False).to_frame().T


#pairplot for numeric values
sns.pairplot(data)


# Function to visualize class imbalance in the dataset
def data_analysis(data, column_name, color, text_width=0.6, bar_width=0.8, bar_length_multiplier=1.0):
    counts = data[column_name].value_counts().values
    cls_names = data[column_name].value_counts().keys()
    width, text_width, text_height = bar_width, text_width, 0.3 * bar_length_multiplier

    fig, ax = plt.subplots(figsize=(20, 10))
    indices = np.arange(len(counts))

    ax.bar(indices, counts, width * bar_length_multiplier, color=color)
    ax.set_xlabel("Class Names", color="red")
    ax.set_xticklabels(cls_names, rotation=90)
    ax.set(xticks=indices, xticklabels=cls_names)
    ax.set_ylabel("Data Counts", color="red")
    ax.set_title(f"Dataset Class Imbalance Analysis")

    for i, v in enumerate(counts):
        ax.text(i - text_width, v + text_height, str(v), color="black", fontweight="bold")

# Example call with changes
data_analysis(data=data, column_name="job_title", color="skyblue", bar_width=0.5, bar_length_multiplier=1.5)


#correlation between job title and salary
plt.figure(figsize=(40, 10))
sns.barplot(x='job_title', y='salary_in_usd', data=data)


#class imbalance
def data_analysis(data, column_name, color, text_width=0.6, bar_width=0.8, bar_length_multiplier=1.0):
    counts = data[column_name].value_counts().values
    cls_names = data[column_name].value_counts().keys()
    width, text_width, text_height = bar_width, text_width, 0.3 * bar_length_multiplier

    fig, ax = plt.subplots(figsize=(20, 10))
    indices = np.arange(len(counts))

    ax.bar(indices, counts, width * bar_length_multiplier, color=color)
    ax.set_xlabel("Class Names", color="red")
    ax.set_xticklabels(cls_names, rotation=90)
    ax.set(xticks=indices, xticklabels=cls_names)
    ax.set_ylabel("Data Counts", color="red")
    ax.set_title(f"Dataset Class Imbalance Analysis")

    for i, v in enumerate(counts):
        ax.text(i - text_width, v + text_height, str(v), color="royalblue")

# Example call with changes
data_analysis(data=data, column_name="experience_level", color="skyblue", bar_width=0.5, bar_length_multiplier=1.5)


#correlation between experience level and salary
plt.figure(figsize=(40, 8))
sns.boxenplot(x='experience_level', y='salary_in_usd', data=data)


#mean salaries for different jobs in the usa
job_title_means = [(i, np.mean(data['salary'][(data['job_title']==i) & (data['employee_residence']=='United States')])) for i in data['job_title'].unique()]

sorted_job_title_means = sorted(job_title_means, key=lambda x: x[1], reverse=True)

for title, mean_salary in sorted_job_title_means:
    print(f'The mean salary of {title} in U.S is {mean_salary}')


def clean_data(data, column_names, threshold = 10):
    
    for column_name in column_names:
        titles = list(data[column_name])
        di = {}
        for title in titles:
            if title not in di: di[title] = 1
            else: di[title] += 1

        li = [key for (key, value) in di.items() if value < threshold]
        
        for name in li:
            mask = data[column_name] == name
            data = data[~mask]
        return data

column_names = ["job_title", "company_location", "employee_residence"]
print(f"Before length: {len(data)}")
data = clean_data(data = data, column_names = column_names)
print(f"After length:  {len(data)}")


features = ["job_title", "experience_level", "employment_type", "work_models", "work_year", "employee_residence", "company_location", "company_size"]
label = ["salary_in_usd"]

X, y = data[features], data[label]
X.head()


y.head()


#split the dataset
# 80% training and 20% test
X_train, X_test,y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2024) 



#preprocessing
num_features = ["work_year"]
str_features = ["job_title", "experience_level", "employment_type", "work_models", "employee_residence", 
                "company_location", "company_size"]

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder

num_converter = Pipeline(steps = [("scaler", StandardScaler())])
str_converter = Pipeline(steps = [("onehot", OneHotEncoder())])
print(num_converter); print(str_converter)


data_train = y_train["salary_in_usd"]
before = data_train
print(f"Before transformation:\n{before[:10]}")
after = num_converter.fit_transform(np.array(data_train).reshape(-1, 1))
print(f"After transformation:\n{after[:10]}")






before = X_train[str_features]
print(f"Before transformation:\n{before[:5]}")
after = str_converter.fit_transform((X_train[str_features])).toarray()
print(f"After transformation:\n{after[:5]}")


print(y_train)






